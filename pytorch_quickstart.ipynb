{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7158f4",
   "metadata": {},
   "source": [
    "# Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dae5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f900d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the heart of PyTorch data loading utility is the torch.utils.data.DataLoader class. It represents a Python iterable over a dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92028e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets.\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee71799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In PyTorch and torchvision, the purpose of transform is to preprocess and augment data,\n",
    "# especially images, before feeding them into a neural network\n",
    "# v2 is newer API and recommend to use ToImage and ToDtype  in place of ToTensor.\n",
    "import torchvision.transforms.v2 as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6c5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),       # Converts input (like PIL images or NumPy arrays) into PyTorch image format (C × H × W, i.e., Channels, Height, Width).\n",
    "    transforms.ToDtype(torch.float32, scale=True)       # Scales pixel values from [0, 255] to [0.0, 1.0] and changes data type.\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92622d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',            # Downloads or looks for the data in the ./data/ directory.\n",
    "    train=True,             # Whether to load training or test split.\n",
    "    download=True,          # Automatically downloads if not found.\n",
    "    transform=transform     # Applies the transform defined above to every image.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c3d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb8c5b",
   "metadata": {},
   "source": [
    "DataLoader\n",
    "    Wraps the datasets in a DataLoader, which:\n",
    "\n",
    "        Automatically batches the data (64 images per batch).\n",
    "\n",
    "        Shuffles training data by default (unless disabled).\n",
    "\n",
    "        Allows iterating through the dataset efficiently.\n",
    "\n",
    "        Supports multiprocessing for faster loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "222ce1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Max = 1.0 and Min is 0.0\n"
     ]
    }
   ],
   "source": [
    "# We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset,\n",
    "# and supports automatic batching, sampling, shuffling and multiprocess data loading\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    print(f\"Max = {X.max().item()} and Min is {X.min().item()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1fa2e",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be5295",
   "metadata": {},
   "source": [
    "To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468bbe6",
   "metadata": {},
   "source": [
    "To accelerate operations in the neural network, we move it to the accelerator such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f92a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0aff039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f87efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating a new custom model by subclassing nn.Module—this is the standard way to define neural networks in PyTorch.\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()                          # super().__init__() calls the parent class constructor (nn.Module)\n",
    "        self.flatten = nn.Flatten()                 # Flatten the Image shape: [N, 1, 28, 28] to reshapes this into [N, 784]\n",
    "        self.linear_relu_stack = nn.Sequential(     # Define the Neural Network\n",
    "            nn.Linear(28*28, 512),                  # nn.Linear(in_features, out_features) defines a fully connected layer.\n",
    "            nn.ReLU(),                              # introduces non-linearity.\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):                           # defines how data moves through the network.\n",
    "        X = self.flatten(X)\n",
    "        logits = self.linear_relu_stack(X)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)                  # to(device) moves the model to GPU or CPU depending on what you've defined earlier\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f550c0",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad38b98",
   "metadata": {},
   "source": [
    "To train a model, we need a loss function and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af44587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8550b99",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model’s parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4364c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)  # Total number of training examples, used for logging.\n",
    "    model.train()       # Puts model in training mode (enables dropout, batch norm, etc. if used).\n",
    "    for batch, (X, y) in enumerate(dataloader):     # Loops over the dataloader, which yields mini-batches of input (X) and label (y).\n",
    "        X, y = X.to(device), y.to(device)           # Moves the batch to the correct device (CPU or GPU).\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)                             # Get model output (logits) for the input X\n",
    "        loss = loss_fn(pred, y)                     # Compare predictions (pred) to ground truth labels (y) using the provided loss_fn\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()                             # Computes gradients using backpropagation\n",
    "        optimizer.step()                            # Updates model weights using the gradients.\n",
    "        optimizer.zero_grad()                       # Clears gradients before the next step (important to prevent accumulation).\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)       # The current loss (converted to a Python number via .item())\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")  # current is number of samples processed so far: (batch + 1) * batch_size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ada804",
   "metadata": {},
   "source": [
    "We also check the model’s performance against the test dataset to ensure it is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c46e5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()                            # Set model to evaluation mode\n",
    "    test_loss, correct = 0, 0               # Initialize loss and accuracy counters\n",
    "    with torch.no_grad():                   # Turn Off Gradient Tracking, Gradient only required while model is learning,\n",
    "                                            # saves memory & speeds up computation.\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()                                # Accumulate Loss, .item() converts a single-value tensor to a standard Python float.\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()     # Count Correct Predictions,\n",
    "                                                                                # pred.argmax(1): Gets the index of the max logit (predicted class).\n",
    "        test_loss /= num_batches            # Calculate Average Loss and Accuracy\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf56bf",
   "metadata": {},
   "source": [
    "The training process is conducted over several iterations (epochs). During each epoch, the model learns parameters to make better predictions. We print the model’s accuracy and loss at each epoch; we’d like to see the accuracy increase and the loss decrease with every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf7cdf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.310946  [   64/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.298762  [ 6464/60000]\n",
      "loss: 2.279612  [12864/60000]\n",
      "loss: 2.273447  [19264/60000]\n",
      "loss: 2.260120  [25664/60000]\n",
      "loss: 2.231806  [32064/60000]\n",
      "loss: 2.246035  [38464/60000]\n",
      "loss: 2.211257  [44864/60000]\n",
      "loss: 2.211536  [51264/60000]\n",
      "loss: 2.181599  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 33.9%, Avg loss: 2.178273 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.191308  [   64/60000]\n",
      "loss: 2.180477  [ 6464/60000]\n",
      "loss: 2.134054  [12864/60000]\n",
      "loss: 2.149364  [19264/60000]\n",
      "loss: 2.102354  [25664/60000]\n",
      "loss: 2.046243  [32064/60000]\n",
      "loss: 2.085636  [38464/60000]\n",
      "loss: 2.010016  [44864/60000]\n",
      "loss: 2.015189  [51264/60000]\n",
      "loss: 1.952966  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.951010 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.980870  [   64/60000]\n",
      "loss: 1.949572  [ 6464/60000]\n",
      "loss: 1.852822  [12864/60000]\n",
      "loss: 1.892917  [19264/60000]\n",
      "loss: 1.778928  [25664/60000]\n",
      "loss: 1.726599  [32064/60000]\n",
      "loss: 1.759982  [38464/60000]\n",
      "loss: 1.655093  [44864/60000]\n",
      "loss: 1.671667  [51264/60000]\n",
      "loss: 1.575426  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.591966 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.651869  [   64/60000]\n",
      "loss: 1.608047  [ 6464/60000]\n",
      "loss: 1.471824  [12864/60000]\n",
      "loss: 1.542055  [19264/60000]\n",
      "loss: 1.411652  [25664/60000]\n",
      "loss: 1.399850  [32064/60000]\n",
      "loss: 1.416270  [38464/60000]\n",
      "loss: 1.336720  [44864/60000]\n",
      "loss: 1.363515  [51264/60000]\n",
      "loss: 1.263830  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.297749 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.373391  [   64/60000]\n",
      "loss: 1.343762  [ 6464/60000]\n",
      "loss: 1.189626  [12864/60000]\n",
      "loss: 1.291788  [19264/60000]\n",
      "loss: 1.160442  [25664/60000]\n",
      "loss: 1.179444  [32064/60000]\n",
      "loss: 1.196331  [38464/60000]\n",
      "loss: 1.135041  [44864/60000]\n",
      "loss: 1.165724  [51264/60000]\n",
      "loss: 1.082111  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.112173 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef77b39d",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961e9b9",
   "metadata": {},
   "source": [
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c64c2711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to saved_model/model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"saved_models/model.pth\")\n",
    "print(\"Saved PyTorch Model State to saved_model/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88c9cb",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3b693",
   "metadata": {},
   "source": [
    "The process for loading a model includes re-creating the model structure and loading the state dictionary into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab6bc224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"saved_models/model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec173aa",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0baf0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcff296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
